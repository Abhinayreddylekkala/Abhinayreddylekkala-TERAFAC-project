Terafac Placement Drive - Autonomous Robot Navigation
This repository contains my solution for the autonomous collision-free route planning task. The goal was to develop a self-driving robot to navigate increasingly complex environments with minimal collisions.

Video Deliverables
Level 1 (Static Obstacles): [Link to your Level 1 Video Here]

Level 2 (Moving Obstacles): [Link to your Level 2 Video Here]

Level 3 (Analysis Graph): The graph is generated by the script and saved as speed_vs_collisions_graph.png. A copy is included below for reference.

Technical Approach
My approach focused on creating a robust and resilient navigation system despite significant limitations discovered in the provided simulator API.

Key Challenge: Incomplete Simulator API
Upon initial investigation, I determined that the provided server.py file does not include an HTTP endpoint to retrieve camera images. The /capture endpoint is a POST request that only sends a command to the simulator, but there is no mechanism to send the resulting image data back to the Python controller via HTTP.

This makes a purely computer-vision-based navigation solution (as required by the prompt) impossible without modifying the simulator's core code or implementing a complex WebSocket client to intercept the image data.

Solution: Intelligent "Blind" Navigation with Randomized Escape
To overcome this critical limitation, I engineered an intelligent "blind" navigation algorithm that uses the only reliable feedback from the environment: collisions. This demonstrates a practical, real-world approach to problem-solving when faced with imperfect tools.

The core logic is a state machine combined with a randomized escape maneuver:

Seeking Mode: The robot's default state is to actively seek the goal. It uses an internal "compass" to calculate the shortest turn towards the target corner and steers itself accordingly.

Avoiding Mode: When a collision is detected, the robot's priority is to get unstuck. It executes a powerful escape maneuver:

It reverses a set distance to disengage from the obstacle.

It performs a large, randomized turn (between 120 and 180 degrees). This unpredictability is key to breaking it out of complex traps and corners where a fixed turn would fail.

It moves forward slightly to clear the crash site before returning to Seeking Mode.

This strategy creates a robot that is both a determined goal-seeker and a clever escape artist, allowing it to effectively navigate the maze and reach the goal corners.

How to Run the Code
Setup the Simulator:

Clone the sim-1 repository: git clone https://github.com/terafac/sim-1.git

Navigate into the folder: cd sim-1

Install the necessary libraries: pip install Flask Flask-SocketIO numpy opencv-python Pillow

Run the server: python server.py

Open the index.html file in a web browser.

Run the Controller:

Clone this repository.

Navigate into the project folder.

Install the required libraries: pip install matplotlib websocket-client

Open the robot_controller.py script and set the CHALLENGE_TO_RUN variable at the bottom to "LEVEL_1", "LEVEL_2", or "LEVEL_3".

Run the script from your terminal: python robot_controller.py